"""
fast_train.py
DO NOT EDIT THIS FILE! THIS FILE IS AUTO-GENERATED!
"""

import numpy as np
import torch
from torch.utils.data import TensorDataset, DataLoader

from data_utils import WrappedDataLoader

class DataConversion():

    @staticmethod
    def np_int2np_binary(np_int_data:np.array, num_channels:np.array)->np.array:
        """
        Convert 2d arrays of integers to 3d arrays of zeros and ones using one-hot encoding.
        
        :param np_int_data: an array of to-be-converted 2d arrays, shape: (bs, height, width)
        :param num_channels: the depth of the to-be-outputted 3d arrays
        :return an array of 3d arrays, shape: (bs, height, width, num_channels)
        """
        return np.eye(num_channels)[int_data]

    @staticmethod
    def np_array2torch_tensor(np_array:np.array)->torch.Tensor:
        """Convert an NumPy array to a PyTorch tensor."""
        return torch.from_numpy(np_array)

    @staticmethod
    def get_dl(torch_xs:torch.Tensor, torch_ys:torch.Tensor, bs:int, shuffle:bool, preprocess_func=None)->WrappedDataLoader:
        """
        Convert two PyTorch tensors to a WrappedDataLoader.
        
        :param xs: a PyTorch tensor of training examples with the zeroth axis being the batch axis
        :param ys: a PyTorch tensor of training targets with the zeroth axis being the batch axis
        :param bs: batch size
        :param shuffle: whether training examples and targets are shuffled, True for training, False for validation
        :param preprocess_func: a function that inputs a batch of training examples and targets, do something with them,
            and outputs them
        :return a WrappedDataLoader instance that can be used directly for training
        """
        ds = TensorDataset(xs, ys)
        dl = DataLoader(ds, batch_size=bs, shuffle=shuffle)
        wrapped_dl = WrappedDataLoader(dl, preprocess_func)
        return wrapped_dl

class DataPreprocess():

    @staticmethod
    def to_cuda(xs:torch.Tensor, ys:torch.Tensor)->tuple:
        """Convert two PyTorch tensors to double-precision and put them on GPU."""
        assert torch.cuda.is_available(), AssertionError('Preprocessing function `to_cuda` only works when GPU is available.')
        return xs.double().to(torch.device('cuda')), ys.double().to(torch.device('cuda'))

class DataPipeline():

    @staticmethod
    def binary_vae(np_int_imgs:np.array, bs:int, shuffle:bool=True):
        """
        Convert an array of 2d arrays of integers to a WrappedDataLoader that can be used to train a binary VAE.
        A binary VAE is a VAE that takes in and outputs one-hot encoded arrays.
        
        :param np_int_imgs: an array of 2d arrays of integers, shape: (bs, height, width)
        :param bs: batch_size
        :param shuffle: whether training examples and targets are shuffled, True for training, False for validation
        :return a WrappedDataLoader instance that can be used directly for training a binary VAE
        """
        np_binary_imgs = DataConversion.np_int2np_binary(np_int_imgs)
        torch_binary_imgs = DataConversion.np_array2torch_tensor(np_binary_imgs)
        dl = DataConversion.get_dl(
            xs=torch_binary_imgs, ys=torch_binary_imgs, 
            bs=bs, shuffle=shuffle, 
            preprocess_func=DataPreprocess.to_cuda
        )
        return dl

