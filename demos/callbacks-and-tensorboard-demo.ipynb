{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.459349Z",
     "start_time": "2019-12-17T08:05:02.520411Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import shutil\n",
    "import scipy.misc\n",
    "\n",
    "import sys\n",
    "sys.path.append('../modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with `state_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.466438Z",
     "start_time": "2019-12-17T08:05:04.462019Z"
    }
   },
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    \n",
    "    state_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.476590Z",
     "start_time": "2019-12-17T08:05:04.471358Z"
    }
   },
   "outputs": [],
   "source": [
    "class CallbackA(Callback): \n",
    "    \n",
    "    def print_state_dict(self):\n",
    "        print(self.state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.501782Z",
     "start_time": "2019-12-17T08:05:04.485934Z"
    }
   },
   "outputs": [],
   "source": [
    "class CallbackB(Callback): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.548910Z",
     "start_time": "2019-12-17T08:05:04.513397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CallbackA.state_dict == CallbackB.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.567345Z",
     "start_time": "2019-12-17T08:05:04.554129Z"
    }
   },
   "outputs": [],
   "source": [
    "CallbackB.state_dict.update({'apple':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When CallbackB makes a change to its state_dict, CallbackA also perceives that change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.577947Z",
     "start_time": "2019-12-17T08:05:04.570298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CallbackA.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.597508Z",
     "start_time": "2019-12-17T08:05:04.585659Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_a, cb_b = CallbackA(), CallbackB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.606613Z",
     "start_time": "2019-12-17T08:05:04.601501Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_a.state_dict.update({'pear':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.612953Z",
     "start_time": "2019-12-17T08:05:04.608728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple': 1, 'pear': 2}\n"
     ]
    }
   ],
   "source": [
    "cb_a.print_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.622053Z",
     "start_time": "2019-12-17T08:05:04.616388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1, 'pear': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_b.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.630617Z",
     "start_time": "2019-12-17T08:05:04.623833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1, 'pear': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CallbackA.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner\n",
    "container for data, model, loss_fn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.638093Z",
     "start_time": "2019-12-17T08:05:04.632835Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Learner():\n",
    "    def __init__(self, train_data, model, loss, optim, valid_data=None):\n",
    "        self.train_data, self.model, self.loss, self.optim, self.valid_data = train_data, model, loss, optim, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback base class, custom callbacks, CallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.649252Z",
     "start_time": "2019-12-17T08:05:04.641062Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Callback(): \n",
    "    sd = {}\n",
    "    def on_train_begin(self): pass  # make sure to reset self.sd because it is a class attribute\n",
    "    def on_epoch_begin(self): pass\n",
    "    def on_batch_begin(self): pass\n",
    "    def on_loss_begin(self): pass\n",
    "    def on_backward_begin(self): pass\n",
    "    def on_backward_end(self): pass\n",
    "    def on_step_end(self): pass\n",
    "    def on_batch_end(self): pass\n",
    "    def on_epoch_end(self): pass\n",
    "    def on_train_end(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.665657Z",
     "start_time": "2019-12-17T08:05:04.652703Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CallbackHandler(Callback): \n",
    "    \n",
    "    def __init__(self, cbs):\n",
    "        self.cbs = cbs\n",
    "    \n",
    "    def __call__(self, cb_category:str):\n",
    "        self.cbs = sorted(self.cbs, key=lambda cb : cb._order)\n",
    "        for cb in self.cbs: getattr(cb, cb_category)()\n",
    "    \n",
    "    def on_train_begin(self): self('on_train_begin')\n",
    "        \n",
    "    def on_epoch_begin(self): self('on_epoch_begin')\n",
    "    \n",
    "    def on_batch_begin(self): self('on_batch_begin')\n",
    "        \n",
    "    def on_loss_begin(self): self('on_loss_begin')\n",
    "        \n",
    "    def on_backward_begin(self): self('on_backward_begin')\n",
    "        \n",
    "    def on_backward_end(self): self('on_backward_end')\n",
    "        \n",
    "    def on_step_end(self): self('on_step_end')\n",
    "        \n",
    "    def on_batch_end(self): self('on_batch_end')\n",
    "    \n",
    "    def on_epoch_end(self): self('on_epoch_end')\n",
    "        \n",
    "    def on_train_end(self): self('on_train_end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.679287Z",
     "start_time": "2019-12-17T08:05:04.668486Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def ifoverwrite(overwrite:bool, file_navigator:str, file_navigator_type:str)->None:\n",
    "    \n",
    "    if overwrite:\n",
    "        \n",
    "        if file_navigator_type == 'path':\n",
    "            file_dir = ''.join([folder + '/' for folder in file_navigator.split('/')[:-1]])\n",
    "            if not (os.path.isfile(file_navigator_type) or os.path.isdir(file_dir)):\n",
    "                os.makedirs(file_dir, exist_ok=True)\n",
    "            \n",
    "        elif file_navigator_type == 'dir':\n",
    "            file_dir = file_navigator\n",
    "            if os.path.isdir(file_dir):  # so that overwrite also works when there's nothing to overwrite\n",
    "                shutil.rmtree(file_dir)\n",
    "                os.makedirs(file_dir, exist_ok=False)\n",
    "            \n",
    "    else:\n",
    "        assert not (os.path.isfile(file_navigator) or os.path.isdir(file_navigator)), \\\n",
    "        AssertionError(f'{file_navigator} already exists. To overwrite it, pass True to argument `overwrite`.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.698575Z",
     "start_time": "2019-12-17T08:05:04.685583Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TensorboardCreator(Callback):\n",
    "    _order=0\n",
    "    \n",
    "    def __init__(self, log_dir, overwrite:bool):\n",
    "        self.log_dir = log_dir\n",
    "        ifoverwrite(overwrite, log_dir, 'dir')\n",
    "    \n",
    "    def on_train_begin(self):\n",
    "        self.sd.update({'writer':SummaryWriter(log_dir=self.log_dir)})\n",
    "        \n",
    "    def on_train_end(self):\n",
    "        self.sd['writer'].flush()\n",
    "        self.sd['writer'].close()\n",
    "        del self.sd['writer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.718089Z",
     "start_time": "2019-12-17T08:05:04.703478Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MetricLogger(Callback):\n",
    "    \"\"\"Log (in a list) and visualize metric values over time.\"\"\"\n",
    "    _order=1\n",
    "    \n",
    "    def __init__(self, metric_name:str, group:str, on_tensorboard:bool):\n",
    "        \n",
    "        self.metric_name = metric_name\n",
    "        self.group = group\n",
    "        self.on_tensorboard = on_tensorboard\n",
    "\n",
    "    def on_train_begin(self):\n",
    "        self.sd[f'last_{self.metric_name}'] = None\n",
    "        self.sd[f'{self.metric_name}s'] = []\n",
    "\n",
    "    def on_epoch_begin(self):\n",
    "        self.total = 0\n",
    "        self.num_examples = 0\n",
    "    \n",
    "    def on_batch_end(self):\n",
    "        self.total += self.sd[f'{self.metric_name}_b']\n",
    "        self.num_examples += self.sd['batch_size'] \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        last = self.total / self.num_examples\n",
    "        self.sd[f'last_{self.metric_name}'] = last\n",
    "        self.sd[f'{self.metric_name}s'].append(last)\n",
    "        \n",
    "        if self.on_tensorboard:\n",
    "            self.sd['writer'].add_scalar(\n",
    "                f'{self.group}/{self.metric_name}', \n",
    "                self.sd[f'last_{self.metric_name}'], \n",
    "                self.sd['epoch']\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.731658Z",
     "start_time": "2019-12-17T08:05:04.720082Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MetricsSaver(Callback):\n",
    "    \"\"\"\n",
    "    Log metric values over time into a csv that can be loaded and visualized within a jupyter notebook.\n",
    "    \n",
    "    Depend on MetricRecorder to work properly.\n",
    "    \"\"\"\n",
    "    _order=2\n",
    "    \n",
    "    def __init__(self, metrics_to_log:list, csv_path:str, overwrite:bool):\n",
    "        \"\"\"\n",
    "        :param metrics_to_log: a list of names of the metrics to log\n",
    "            - make sure that an accumulator for each metric is available in self.sd\n",
    "            - make sure to add an 's' to each metric name\n",
    "            - do not add 'epochs' to this list, since it will be obvious during plotting\n",
    "        \"\"\"\n",
    "        self.metrics_to_log = metrics_to_log\n",
    "        self.csv_path = csv_path\n",
    "        ifoverwrite(overwrite, csv_path, 'path')\n",
    "    \n",
    "    def on_train_end(self):\n",
    "        loss_df = pd.DataFrame(np.array([self.sd[m] for m in self.metrics_to_log]).T)\n",
    "        loss_df.columns = self.metrics_to_log\n",
    "        loss_df.to_csv(self.csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.746750Z",
     "start_time": "2019-12-17T08:05:04.739469Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenLogger(Callback):\n",
    "    \"\"\"Visualize generated arrays for generative models.\"\"\"\n",
    "    _order=1\n",
    "    \n",
    "    def __init__(self, gen_name:str, group:str):\n",
    "        self.gen_name = gen_name\n",
    "        self.group = group\n",
    "\n",
    "    def on_epoch_end(self):        \n",
    "        self.sd['writer'].add_images(\n",
    "            f'{self.group}/{self.gen_name}', \n",
    "            self.sd[self.gen_name],\n",
    "            global_step=self.sd['epoch']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.753354Z",
     "start_time": "2019-12-17T08:05:04.749580Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# class GensSaver(Callback):\n",
    "#     \"\"\"Log (in a directory) generated arrays for generative models.\"\"\"\n",
    "#     _order=2\n",
    "#     def __init__(self, )\n",
    "    \n",
    "#     for gen in self.sd[gen_name]:  # self.sd[gen_name] is of shape (N, C, H, W)\n",
    "#             scipy.misc.imsave('outfile.jpg', image_array)\n",
    "#             plt.savefig(gen.detach()., dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.763206Z",
     "start_time": "2019-12-17T08:05:04.756273Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ModelSaver(Callback):\n",
    "    _order=2\n",
    "    \n",
    "    def __init__(self, model_path:str, overwrite:bool): \n",
    "        self.model_path = model_path\n",
    "        ifoverwrite(overwrite, model_path, 'path')\n",
    "    \n",
    "    def on_train_end(self):\n",
    "        torch.save(self.sd['model'].state_dict(), self.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.786027Z",
     "start_time": "2019-12-17T08:05:04.770346Z"
    }
   },
   "outputs": [],
   "source": [
    "def fake_train(cb_handler):\n",
    "    cb_handler.on_train_begin()\n",
    "    for i in range(255):\n",
    "        cb_handler.on_epoch_begin()\n",
    "        for j in range(10):\n",
    "            cb_handler.on_batch_begin()\n",
    "            cb_handler.on_loss_begin()\n",
    "            cb_handler.sd.update({\n",
    "                'model':torch.nn.Linear(5, 10),\n",
    "                'epoch':i, \n",
    "                'batch_size':64, \n",
    "                'bce_loss_b':np.random.random()*64\n",
    "            })\n",
    "            cb_handler.on_backward_begin()\n",
    "            cb_handler.on_backward_end()\n",
    "            cb_handler.on_step_end()\n",
    "            cb_handler.on_batch_end()\n",
    "        cb_handler.sd.update({'gen':torch.ones((5, 3, 2, 2))*cb_handler.sd['epoch']})\n",
    "        cb_handler.on_epoch_end()\n",
    "    cb_handler.on_train_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.796298Z",
     "start_time": "2019-12-17T08:05:04.790384Z"
    }
   },
   "outputs": [],
   "source": [
    "# these may serve as arguments for VAETrainer\n",
    "# caution: overwrites do not show up immediately on tensorboard; you may need to restart it in terminal :<\n",
    "exp_name = 'testing_callbacks'\n",
    "trial = 4\n",
    "overwrite_vis = True\n",
    "overwrite_csv = True\n",
    "overwrite_pth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:08.078893Z",
     "start_time": "2019-12-17T08:05:04.800567Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_handler = CallbackHandler([\n",
    "    TensorboardCreator(log_dir=f'runs/{exp_name}/{trial}', overwrite=overwrite_vis),  # automatically mkdir\n",
    "    MetricLogger(metric_name='bce_loss', group='train', on_tensorboard=True),\n",
    "    MetricsSaver(metrics_to_log=['bce_losss'], csv_path=f'training_csv/{exp_name}/{trial}.csv', overwrite=overwrite_csv),\n",
    "    GenLogger(gen_name='gen', group='group1'),\n",
    "    ModelSaver(model_path=f'trained_models/{exp_name}/{trial}.pth', overwrite=overwrite_pth)\n",
    "])\n",
    "fake_train(cb_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:12:06.257095Z",
     "start_time": "2019-12-16T12:12:06.216525Z"
    }
   },
   "source": [
    "## VAETrainer\n",
    "container for a training loop involving a Learner object, custom callbacks and a CallbackHandler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:08.091448Z",
     "start_time": "2019-12-17T08:05:08.080883Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAETrainer(CallbackHandler):\n",
    "    \n",
    "    def __init__(self, learn, cbs):\n",
    "        self.learn = learn\n",
    "        self.cbs = cbs\n",
    "        \n",
    "    def train(self, num_epochs):\n",
    "        self.on_train_begin()  # create empty accumulators\n",
    "        print('finished on train begin')\n",
    "        for epoch in range(num_epochs):\n",
    "            self.on_epoch_begin()\n",
    "            print('finished on epoch begin')\n",
    "            for xb, yb in self.learn.train_data:\n",
    "                \n",
    "                self.on_batch_begin()\n",
    "                print('finished on batch begin')\n",
    "                \n",
    "                recon, mu, logvar = self.learn.model(xb)\n",
    "                \n",
    "                self.on_loss_begin()\n",
    "                print('finished on loss begin')\n",
    "                loss, bce, kld = self.learn.loss(recon, yb, mu, logvar)\n",
    "                \n",
    "                self.on_backward_begin()\n",
    "                loss.backward()\n",
    "                self.on_backward_end()\n",
    "                self.learn.optim.step()\n",
    "                self.on_step_end()\n",
    "                \n",
    "                self.sd.update({\n",
    "                    'model':self.learn.model,\n",
    "                    'epoch':epoch+1, \n",
    "                    'batch_size':int(xb.size(0)), \n",
    "                    'loss_b':float(loss), \n",
    "                    'bce_b':float(bce), \n",
    "                    'kld_b':float(kld)\n",
    "                })\n",
    "                \n",
    "                self.on_batch_end()\n",
    "            gens = self.learn.model.generate(n=10)\n",
    "            self.sd.update({'gens':gens})\n",
    "            self.on_epoch_end()  # calculate average loss per example, visualize metrics, perform validation if required\n",
    "        self.on_train_end()  # close tensorboard writer, output csv of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data as dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:08.610933Z",
     "start_time": "2019-12-17T08:05:08.094443Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from fast_train import DataPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:14.502403Z",
     "start_time": "2019-12-17T08:05:14.147705Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:16.218577Z",
     "start_time": "2019-12-17T08:05:14.862642Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train.mean()) / x_train.std()\n",
    "x_train = np.expand_dims(x_train, axis=1)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:16.228350Z",
     "start_time": "2019-12-17T08:05:16.221742Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:16.695318Z",
     "start_time": "2019-12-17T08:05:16.689037Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataPipeline.float_vae(x_train, bs=16)\n",
    "del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:17.432570Z",
     "start_time": "2019-12-17T08:05:17.422750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28]) torch.Size([16, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "a, b = next(iter(train_dl))\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:18.292742Z",
     "start_time": "2019-12-17T08:05:18.284067Z"
    }
   },
   "outputs": [],
   "source": [
    "from vae_designer import VAEDesigner\n",
    "from custom_vae import VAEDesign\n",
    "designer_on = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:18.622754Z",
     "start_time": "2019-12-17T08:05:18.612929Z"
    }
   },
   "outputs": [],
   "source": [
    "if designer_on:\n",
    "    dec_designer = VAEDesigner(input_shape=(1, 28, 28), up_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:18.807845Z",
     "start_time": "2019-12-17T08:05:18.801116Z"
    }
   },
   "outputs": [],
   "source": [
    "if designer_on:\n",
    "    print(dec_designer.design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:19.083516Z",
     "start_time": "2019-12-17T08:05:19.077057Z"
    }
   },
   "outputs": [],
   "source": [
    "if designer_on:\n",
    "    enc_designer = VAEDesigner(input_shape=(3, 5, 5), up_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:19.271338Z",
     "start_time": "2019-12-17T08:05:19.265768Z"
    }
   },
   "outputs": [],
   "source": [
    "if designer_on:\n",
    "    print(enc_designer.design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:19.435112Z",
     "start_time": "2019-12-17T08:05:19.426781Z"
    }
   },
   "outputs": [],
   "source": [
    "if designer_on:\n",
    "    vae_design = VAEDesign(\n",
    "        down_sampler_design=dec_designer.design, \n",
    "        up_sampler_design=enc_designer.design, \n",
    "        h_dim=64, \n",
    "        z_dim=3, \n",
    "        unflatten_out_shape=(64, 1, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:19.752198Z",
     "start_time": "2019-12-17T08:05:19.747391Z"
    }
   },
   "outputs": [],
   "source": [
    "if designer_on:\n",
    "    vae_design.save_as_json('designs/mnist_vae.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:20.462528Z",
     "start_time": "2019-12-17T08:05:20.458608Z"
    }
   },
   "outputs": [],
   "source": [
    "from custom_vae import get_vae_and_opt\n",
    "from fast_train import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:20.801344Z",
     "start_time": "2019-12-17T08:05:20.785480Z"
    }
   },
   "outputs": [],
   "source": [
    "vae, opt = get_vae_and_opt('designs/mnist_vae.json', dev='cpu')\n",
    "learner = Learner(train_data=train_dl, model=vae, loss=Loss.float_loss_fn, optim=opt, valid_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:21.166729Z",
     "start_time": "2019-12-17T08:05:21.159754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (unflatten): UnFlatten()\n",
       "  (block0-convtranpose2d): ConvTranspose2d(3, 3, kernel_size=(4, 4), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "  (block0-bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (block0-relu): ReLU()\n",
       "  (block1-convtranpose2d): ConvTranspose2d(3, 1, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       "  (block1-bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:21.504702Z",
     "start_time": "2019-12-17T08:05:21.500564Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.zeros((10, 1, 28, 28)).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-17T08:05:21.920Z"
    }
   },
   "outputs": [],
   "source": [
    "vae.encoder(input=a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T07:49:06.150004Z",
     "start_time": "2019-12-17T07:49:06.135371Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-34460ca60281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dl' is not defined"
     ]
    }
   ],
   "source": [
    "vae.encoder(next(iter(train_dl))[0][:10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate callbacks and a trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T05:25:35.174308Z",
     "start_time": "2019-12-17T05:25:35.168458Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_name = 'mnist'\n",
    "trial = 1\n",
    "overwrite_vis = True\n",
    "overwrite_csv = True\n",
    "overwrite_pth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T05:25:36.088609Z",
     "start_time": "2019-12-17T05:25:36.080526Z"
    }
   },
   "outputs": [],
   "source": [
    "vae_cbs = [\n",
    "    TensorboardCreator(log_dir=f'runs/{exp_name}/{trial}', overwrite=overwrite_vis),  # automatically mkdir\n",
    "    MetricLogger(metric_name='loss', group='train', on_tensorboard=True),\n",
    "    MetricLogger(metric_name='bce', group='train', on_tensorboard=True),\n",
    "    MetricLogger(metric_name='kld', group='train', on_tensorboard=True),\n",
    "    MetricsSaver(metrics_to_log=['losss', 'bces', 'klds'], csv_path=f'training_csv/{exp_name}/{trial}.csv', overwrite=overwrite_csv),\n",
    "    GenLogger(gen_name='gen', group='group1'),\n",
    "    ModelSaver(model_path=f'trained_models/{exp_name}/{trial}.pth', overwrite=overwrite_pth)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T05:25:41.823309Z",
     "start_time": "2019-12-17T05:25:41.818241Z"
    }
   },
   "outputs": [],
   "source": [
    "vae_cbs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T05:25:42.035582Z",
     "start_time": "2019-12-17T05:25:42.031949Z"
    }
   },
   "outputs": [],
   "source": [
    "vae_trainer = VAETrainer(learn=learner, cbs=vae_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T05:25:48.160064Z",
     "start_time": "2019-12-17T05:25:48.044698Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vae_trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b7af72d598b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vae_trainer' is not defined"
     ]
    }
   ],
   "source": [
    "vae_trainer.train(num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.444px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
