{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.459349Z",
     "start_time": "2019-12-17T08:05:02.520411Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import shutil\n",
    "import scipy.misc\n",
    "\n",
    "import sys\n",
    "sys.path.append('../modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with `state_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.466438Z",
     "start_time": "2019-12-17T08:05:04.462019Z"
    }
   },
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    \n",
    "    state_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.476590Z",
     "start_time": "2019-12-17T08:05:04.471358Z"
    }
   },
   "outputs": [],
   "source": [
    "class CallbackA(Callback): \n",
    "    \n",
    "    def print_state_dict(self):\n",
    "        print(self.state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.501782Z",
     "start_time": "2019-12-17T08:05:04.485934Z"
    }
   },
   "outputs": [],
   "source": [
    "class CallbackB(Callback): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.548910Z",
     "start_time": "2019-12-17T08:05:04.513397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CallbackA.state_dict == CallbackB.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.567345Z",
     "start_time": "2019-12-17T08:05:04.554129Z"
    }
   },
   "outputs": [],
   "source": [
    "CallbackB.state_dict.update({'apple':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When CallbackB makes a change to its state_dict, CallbackA also perceives that change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.577947Z",
     "start_time": "2019-12-17T08:05:04.570298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CallbackA.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.597508Z",
     "start_time": "2019-12-17T08:05:04.585659Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_a, cb_b = CallbackA(), CallbackB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.606613Z",
     "start_time": "2019-12-17T08:05:04.601501Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_a.state_dict.update({'pear':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.612953Z",
     "start_time": "2019-12-17T08:05:04.608728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple': 1, 'pear': 2}\n"
     ]
    }
   ],
   "source": [
    "cb_a.print_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.622053Z",
     "start_time": "2019-12-17T08:05:04.616388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1, 'pear': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_b.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.630617Z",
     "start_time": "2019-12-17T08:05:04.623833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1, 'pear': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CallbackA.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner\n",
    "container for data, model, loss_fn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.638093Z",
     "start_time": "2019-12-17T08:05:04.632835Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Learner():\n",
    "    def __init__(self, train_data, model, loss, optim, valid_data=None):\n",
    "        self.train_data, self.model, self.loss, self.optim, self.valid_data = train_data, model, loss, optim, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback base class, custom callbacks, CallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.649252Z",
     "start_time": "2019-12-17T08:05:04.641062Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Callback(): \n",
    "    sd = {}\n",
    "    def on_train_begin(self): pass  # make sure to reset self.sd because it is a class attribute\n",
    "    def on_epoch_begin(self): pass\n",
    "    def on_batch_begin(self): pass\n",
    "    def on_loss_begin(self): pass\n",
    "    def on_backward_begin(self): pass\n",
    "    def on_backward_end(self): pass\n",
    "    def on_step_end(self): pass\n",
    "    def on_batch_end(self): pass\n",
    "    def on_epoch_end(self): pass\n",
    "    def on_train_end(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.665657Z",
     "start_time": "2019-12-17T08:05:04.652703Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CallbackHandler(Callback): \n",
    "    \n",
    "    def __init__(self, cbs):\n",
    "        self.cbs = cbs\n",
    "    \n",
    "    def __call__(self, cb_category:str):\n",
    "        self.cbs = sorted(self.cbs, key=lambda cb : cb._order)\n",
    "        for cb in self.cbs: getattr(cb, cb_category)()\n",
    "    \n",
    "    def on_train_begin(self): self('on_train_begin')\n",
    "        \n",
    "    def on_epoch_begin(self): self('on_epoch_begin')\n",
    "    \n",
    "    def on_batch_begin(self): self('on_batch_begin')\n",
    "        \n",
    "    def on_loss_begin(self): self('on_loss_begin')\n",
    "        \n",
    "    def on_backward_begin(self): self('on_backward_begin')\n",
    "        \n",
    "    def on_backward_end(self): self('on_backward_end')\n",
    "        \n",
    "    def on_step_end(self): self('on_step_end')\n",
    "        \n",
    "    def on_batch_end(self): self('on_batch_end')\n",
    "    \n",
    "    def on_epoch_end(self): self('on_epoch_end')\n",
    "        \n",
    "    def on_train_end(self): self('on_train_end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.679287Z",
     "start_time": "2019-12-17T08:05:04.668486Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def ifoverwrite(overwrite:bool, file_navigator:str, file_navigator_type:str)->None:\n",
    "    \n",
    "    if overwrite:\n",
    "        \n",
    "        if file_navigator_type == 'path':\n",
    "            file_dir = ''.join([folder + '/' for folder in file_navigator.split('/')[:-1]])\n",
    "            if not (os.path.isfile(file_navigator_type) or os.path.isdir(file_dir)):\n",
    "                os.makedirs(file_dir, exist_ok=True)\n",
    "            \n",
    "        elif file_navigator_type == 'dir':\n",
    "            file_dir = file_navigator\n",
    "            if os.path.isdir(file_dir):  # so that overwrite also works when there's nothing to overwrite\n",
    "                shutil.rmtree(file_dir)\n",
    "                os.makedirs(file_dir, exist_ok=False)\n",
    "            \n",
    "    else:\n",
    "        assert not (os.path.isfile(file_navigator) or os.path.isdir(file_navigator)), \\\n",
    "        AssertionError(f'{file_navigator} already exists. To overwrite it, pass True to argument `overwrite`.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.698575Z",
     "start_time": "2019-12-17T08:05:04.685583Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TensorboardCreator(Callback):\n",
    "    _order=0\n",
    "    \n",
    "    def __init__(self, log_dir, overwrite:bool):\n",
    "        self.log_dir = log_dir\n",
    "        ifoverwrite(overwrite, log_dir, 'dir')\n",
    "    \n",
    "    def on_train_begin(self):\n",
    "        self.sd.update({'writer':SummaryWriter(log_dir=self.log_dir, flush_secs=2, max_queue=2)})\n",
    "        \n",
    "    def on_train_end(self):\n",
    "        self.sd['writer'].flush()\n",
    "        self.sd['writer'].close()\n",
    "        del self.sd['writer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.718089Z",
     "start_time": "2019-12-17T08:05:04.703478Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MetricLogger(Callback):\n",
    "    \"\"\"Log (in a list) and visualize metric values over time.\"\"\"\n",
    "    _order=1\n",
    "    \n",
    "    def __init__(self, metric_name:str, group:str, on_tensorboard:bool):\n",
    "        \n",
    "        self.metric_name = metric_name\n",
    "        self.group = group\n",
    "        self.on_tensorboard = on_tensorboard\n",
    "\n",
    "    def on_train_begin(self):\n",
    "        self.sd[f'last_{self.metric_name}'] = None\n",
    "        self.sd[f'{self.metric_name}s'] = []\n",
    "\n",
    "    def on_epoch_begin(self):\n",
    "        self.total = 0\n",
    "        self.num_examples = 0\n",
    "    \n",
    "    def on_batch_end(self):\n",
    "        self.total += self.sd[f'{self.metric_name}_b']\n",
    "        self.num_examples += self.sd['batch_size'] \n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        last = self.total / self.num_examples\n",
    "        self.sd[f'last_{self.metric_name}'] = last\n",
    "        self.sd[f'{self.metric_name}s'].append(last)\n",
    "        \n",
    "        if self.on_tensorboard:\n",
    "            self.sd['writer'].add_scalar(\n",
    "                f'{self.group}/{self.metric_name}', \n",
    "                self.sd[f'last_{self.metric_name}'], \n",
    "                self.sd['epoch']\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.731658Z",
     "start_time": "2019-12-17T08:05:04.720082Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MetricsSaver(Callback):\n",
    "    \"\"\"\n",
    "    Log metric values over time into a csv that can be loaded and visualized within a jupyter notebook.\n",
    "    \n",
    "    Depend on MetricRecorder to work properly.\n",
    "    \"\"\"\n",
    "    _order=2\n",
    "    \n",
    "    def __init__(self, metrics_to_log:list, csv_path:str, overwrite:bool):\n",
    "        \"\"\"\n",
    "        :param metrics_to_log: a list of names of the metrics to log\n",
    "            - make sure that an accumulator for each metric is available in self.sd\n",
    "            - make sure to add an 's' to each metric name\n",
    "            - do not add 'epochs' to this list, since it will be obvious during plotting\n",
    "        \"\"\"\n",
    "        self.metrics_to_log = metrics_to_log\n",
    "        self.csv_path = csv_path\n",
    "        ifoverwrite(overwrite, csv_path, 'path')\n",
    "    \n",
    "    def on_train_end(self):\n",
    "        loss_df = pd.DataFrame(np.array([self.sd[m] for m in self.metrics_to_log]).T)\n",
    "        loss_df.columns = self.metrics_to_log\n",
    "        loss_df.to_csv(self.csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.746750Z",
     "start_time": "2019-12-17T08:05:04.739469Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenLogger(Callback):\n",
    "    \"\"\"Visualize generated arrays for generative models.\"\"\"\n",
    "    _order=1\n",
    "    \n",
    "    def __init__(self, gen_name:str, group:str):\n",
    "        self.gen_name = gen_name\n",
    "        self.group = group\n",
    "\n",
    "    def on_epoch_end(self):        \n",
    "        self.sd['writer'].add_images(\n",
    "            f'{self.group}/{self.gen_name}', \n",
    "            self.sd[self.gen_name],\n",
    "            global_step=self.sd['epoch']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debugger(Callback):\n",
    "    _order=100\n",
    "    def __init__(self, on:bool): self.on = on\n",
    "    def on_train_begin(self): \n",
    "        if self.on: print('finished on_train_begin')\n",
    "    def on_epoch_begin(self): \n",
    "        if self.on: print('finished on_epoch_begin')\n",
    "    def on_batch_begin(self): \n",
    "        if self.on: print('finished on_batch_begin')\n",
    "    def on_loss_begin(self): \n",
    "        if self.on: print('finished on_loss_begin')\n",
    "    def on_backward_begin(self): \n",
    "        if self.on: print('finished on_backward_begin')\n",
    "    def on_backward_end(self): \n",
    "        if self.on: print('finished on_backward_end')\n",
    "    def on_step_end(self): \n",
    "        if self.on: print('finished on_step_end')\n",
    "    def on_batch_end(self): \n",
    "        if self.on: print('finished on_batch_end')\n",
    "    def on_epoch_end(self): \n",
    "        if self.on: print('finished on_epoch_end')\n",
    "    def on_train_end(self): \n",
    "        if self.on: print('finished on_train_end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MetricsPrinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsPrinter(Callback):\n",
    "    _order=50\n",
    "    \n",
    "    def __init__(self, metrics_to_print):\n",
    "        self.metrics_to_print = metrics_to_print\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        for m in self.metrics_to_print:\n",
    "            print(f'{m}: {self.sd[m]}', end='|')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.753354Z",
     "start_time": "2019-12-17T08:05:04.749580Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# class GensSaver(Callback):\n",
    "#     \"\"\"Log (in a directory) generated arrays for generative models.\"\"\"\n",
    "#     _order=2\n",
    "#     def __init__(self, )\n",
    "    \n",
    "#     for gen in self.sd[gen_name]:  # self.sd[gen_name] is of shape (N, C, H, W)\n",
    "#             scipy.misc.imsave('outfile.jpg', image_array)\n",
    "#             plt.savefig(gen.detach()., dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.763206Z",
     "start_time": "2019-12-17T08:05:04.756273Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ModelSaver(Callback):\n",
    "    _order=2\n",
    "    \n",
    "    def __init__(self, model_path:str, overwrite:bool): \n",
    "        self.model_path = model_path\n",
    "        ifoverwrite(overwrite, model_path, 'path')\n",
    "    \n",
    "    def on_train_end(self):\n",
    "        torch.save(self.sd['model'].state_dict(), self.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.786027Z",
     "start_time": "2019-12-17T08:05:04.770346Z"
    }
   },
   "outputs": [],
   "source": [
    "def fake_train(cb_handler):\n",
    "    cb_handler.on_train_begin()\n",
    "    for i in range(255):\n",
    "        cb_handler.on_epoch_begin()\n",
    "        for j in range(10):\n",
    "            cb_handler.on_batch_begin()\n",
    "            cb_handler.on_loss_begin()\n",
    "            cb_handler.sd.update({\n",
    "                'model':torch.nn.Linear(5, 10),\n",
    "                'epoch':i, \n",
    "                'batch_size':64, \n",
    "                'bce_loss_b':np.random.random()*64\n",
    "            })\n",
    "            cb_handler.on_backward_begin()\n",
    "            cb_handler.on_backward_end()\n",
    "            cb_handler.on_step_end()\n",
    "            cb_handler.on_batch_end()\n",
    "        cb_handler.sd.update({'gen':torch.ones((5, 3, 2, 2))*cb_handler.sd['epoch']})\n",
    "        cb_handler.on_epoch_end()\n",
    "    cb_handler.on_train_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:04.796298Z",
     "start_time": "2019-12-17T08:05:04.790384Z"
    }
   },
   "outputs": [],
   "source": [
    "# these may serve as arguments for VAETrainer\n",
    "# caution: overwrites do not show up immediately on tensorboard; you may need to restart it in terminal :<\n",
    "exp_name = 'testing_callbacks'\n",
    "trial = 4\n",
    "overwrite_vis = True\n",
    "overwrite_csv = True\n",
    "overwrite_pth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:08.078893Z",
     "start_time": "2019-12-17T08:05:04.800567Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_handler = CallbackHandler([\n",
    "    TensorboardCreator(log_dir=f'runs/{exp_name}/{trial}', overwrite=overwrite_vis),  # automatically mkdir\n",
    "    MetricLogger(metric_name='bce_loss', group='train', on_tensorboard=True),\n",
    "    MetricsSaver(metrics_to_log=['bce_losss'], csv_path=f'training_csv/{exp_name}/{trial}.csv', overwrite=overwrite_csv),\n",
    "    GenLogger(gen_name='gen', group='group1'),\n",
    "    ModelSaver(model_path=f'trained_models/{exp_name}/{trial}.pth', overwrite=overwrite_pth)\n",
    "])\n",
    "fake_train(cb_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:12:06.257095Z",
     "start_time": "2019-12-16T12:12:06.216525Z"
    }
   },
   "source": [
    "## VAETrainer\n",
    "container for a training loop involving a Learner object, custom callbacks and a CallbackHandler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:08.091448Z",
     "start_time": "2019-12-17T08:05:08.080883Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAETrainer(CallbackHandler):\n",
    "    \n",
    "    def __init__(self, learn, cbs):\n",
    "        self.learn = learn\n",
    "        self.cbs = cbs\n",
    "        \n",
    "    def train(self, num_epochs):\n",
    "        self.on_train_begin()  # create empty accumulators\n",
    "        for epoch in range(num_epochs):\n",
    "            self.on_epoch_begin()\n",
    "            for xb, yb in log_progress(self.learn.train_data, name=f'epoch: {epoch+1}'):\n",
    "                \n",
    "                self.on_batch_begin()\n",
    "                \n",
    "                recon, mu, logvar = self.learn.model(xb)\n",
    "                \n",
    "                self.on_loss_begin()\n",
    "                loss, bce, kld = self.learn.loss(recon, yb, mu, logvar)\n",
    "                loss, bce, kld = loss / recon.size(0), bce / recon.size(0), kld / recon.size(0)\n",
    "                \n",
    "                self.on_backward_begin()\n",
    "                loss.backward()\n",
    "                self.on_backward_end()\n",
    "                self.learn.optim.step()\n",
    "                self.on_step_end()\n",
    "                \n",
    "                self.sd.update({\n",
    "                    'model':self.learn.model,\n",
    "                    'epoch':epoch+1, \n",
    "                    'batch_size':int(xb.size(0)), \n",
    "                    'loss_b':float(loss), \n",
    "                    'bce_b':float(bce), \n",
    "                    'kld_b':float(kld)\n",
    "                })\n",
    "                \n",
    "                self.on_batch_end()\n",
    "            gens = self.learn.model.generate(n=10)\n",
    "            gens = torch.cat((gens, gens, gens), axis=1)\n",
    "            self.sd.update({'gens':gens})\n",
    "            self.on_epoch_end()  # calculate average loss per example, visualize metrics, perform validation if required\n",
    "        self.on_train_end()  # close tensorboard writer, output csv of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data as dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:08.610933Z",
     "start_time": "2019-12-17T08:05:08.094443Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from fast_train import DataPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:14.502403Z",
     "start_time": "2019-12-17T08:05:14.147705Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:16.218577Z",
     "start_time": "2019-12-17T08:05:14.862642Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train / x_train.max()\n",
    "x_train = np.expand_dims(x_train, axis=1)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_train.min() >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:16.695318Z",
     "start_time": "2019-12-17T08:05:16.689037Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataPipeline.float_vae(x_train, bs=64)\n",
    "del x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:18.292742Z",
     "start_time": "2019-12-17T08:05:18.284067Z"
    }
   },
   "outputs": [],
   "source": [
    "from vae_designer import VAEDesigner\n",
    "from custom_vae import VAEDesign\n",
    "designer_on = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:18.622754Z",
     "start_time": "2019-12-17T08:05:18.612929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c4e8fee150426c9b1443a93aec6009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='UPSAMPLING MODE'),)), HBox(children=(Button(description='ADD LAYER'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if designer_on:\n",
    "    enc_designer = VAEDesigner(input_shape=(1, 28, 28), up_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:18.807845Z",
     "start_time": "2019-12-17T08:05:18.801116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 1, 'layer_num': 3, 'kernel_nums': (16, 32, 64), 'kernel_sizes': (4, 4, 4), 'strides': (2, 2, 2), 'paddings': (0, 0, 0)}\n"
     ]
    }
   ],
   "source": [
    "if designer_on:\n",
    "    print(enc_designer.design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:19.083516Z",
     "start_time": "2019-12-17T08:05:19.077057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3196ee1379ba439b9aef866acad0a2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='DOWNSAMPLING MODE'),)), HBox(children=(Button(description='ADD LAYE…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if designer_on:\n",
    "    dec_designer = VAEDesigner(input_shape=(64, 1, 1), up_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:19.271338Z",
     "start_time": "2019-12-17T08:05:19.265768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 64, 'layer_num': 3, 'kernel_nums': (32, 16, 1), 'kernel_sizes': (4, 4, 4), 'strides': (2, 2, 2), 'paddings': (0, 0, 0), 'up_sample': True, 'output_paddings': (1, 1, 0)}\n"
     ]
    }
   ],
   "source": [
    "if designer_on:\n",
    "    print(dec_designer.design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:19.435112Z",
     "start_time": "2019-12-17T08:05:19.426781Z"
    }
   },
   "outputs": [],
   "source": [
    "if designer_on:\n",
    "    vae_design = VAEDesign(\n",
    "        down_sampler_design=enc_designer.design, \n",
    "        up_sampler_design=dec_designer.design, \n",
    "        h_dim=64, \n",
    "        z_dim=10, \n",
    "        unflatten_out_shape=(64, 1, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "if designer_on:\n",
    "    vae_design.up_sampler_design['final_activation'] = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:19.752198Z",
     "start_time": "2019-12-17T08:05:19.747391Z"
    }
   },
   "outputs": [],
   "source": [
    "if designer_on:\n",
    "    vae_design.save_as_json('designs/mnist_vae.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_channels': 64,\n",
       " 'layer_num': 3,\n",
       " 'kernel_nums': (32, 16, 1),\n",
       " 'kernel_sizes': (4, 4, 4),\n",
       " 'strides': (2, 2, 2),\n",
       " 'paddings': (0, 0, 0),\n",
       " 'up_sample': True,\n",
       " 'output_paddings': (1, 1, 0),\n",
       " 'final_activation': 'sigmoid'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_design.up_sampler_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "designer_on = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:20.462528Z",
     "start_time": "2019-12-17T08:05:20.458608Z"
    }
   },
   "outputs": [],
   "source": [
    "from custom_vae import get_vae_and_opt\n",
    "from fast_train import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:20.801344Z",
     "start_time": "2019-12-17T08:05:20.785480Z"
    }
   },
   "outputs": [],
   "source": [
    "vae, opt = get_vae_and_opt('designs/mnist_vae.json', dev='cpu')\n",
    "learner = Learner(train_data=train_dl, model=vae, loss=Loss.binary_loss_fn, optim=opt, valid_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:21.166729Z",
     "start_time": "2019-12-17T08:05:21.159754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (block0-conv2d): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       "  (block0-bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (block0-lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  (block1-conv2d): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       "  (block1-bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (block1-lrelu): LeakyReLU(negative_slope=0.2)\n",
       "  (block2-conv2d): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       "  (block2-bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flatten): Flatten()\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (unflatten): UnFlatten()\n",
       "  (block0-convtranpose2d): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "  (block0-bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (block0-relu): ReLU()\n",
       "  (block1-convtranpose2d): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "  (block1-bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (block1-relu): ReLU()\n",
       "  (block2-convtranpose2d): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       "  (block2-bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (block2-sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T08:05:21.504702Z",
     "start_time": "2019-12-17T08:05:21.500564Z"
    }
   },
   "outputs": [],
   "source": [
    "xs = torch.zeros((10, 1, 28, 28)).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-17T08:05:21.920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.encoder(input=xs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = torch.zeros((10, 64, 1, 1)).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.decoder(input=zs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate callbacks and a trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T05:25:35.174308Z",
     "start_time": "2019-12-17T05:25:35.168458Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_name = 'mnist'\n",
    "trial = 1\n",
    "overwrite_vis = True\n",
    "overwrite_csv = True\n",
    "overwrite_pth = True\n",
    "debugger_on = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T05:25:36.088609Z",
     "start_time": "2019-12-17T05:25:36.080526Z"
    }
   },
   "outputs": [],
   "source": [
    "vae_cbs = [\n",
    "    TensorboardCreator(log_dir=f'runs/{exp_name}/{trial}', overwrite=overwrite_vis),  # automatically mkdir\n",
    "    MetricLogger(metric_name='loss', group='train', on_tensorboard=True),\n",
    "    MetricLogger(metric_name='bce', group='train', on_tensorboard=True),\n",
    "    MetricLogger(metric_name='kld', group='train', on_tensorboard=True),\n",
    "    MetricsPrinter(metrics_to_print=['last_loss', 'last_bce', 'last_kld']),\n",
    "    MetricsSaver(metrics_to_log=['losss', 'bces', 'klds'], csv_path=f'training_csv/{exp_name}/{trial}.csv', overwrite=overwrite_csv),\n",
    "    GenLogger(gen_name='gens', group='group1'),\n",
    "    ModelSaver(model_path=f'trained_models/{exp_name}/{trial}.pth', overwrite=overwrite_pth),\n",
    "    Debugger(on=debugger_on),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T05:25:42.035582Z",
     "start_time": "2019-12-17T05:25:42.031949Z"
    }
   },
   "outputs": [],
   "source": [
    "vae_trainer = VAETrainer(learn=learner, cbs=vae_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T05:25:48.160064Z",
     "start_time": "2019-12-17T05:25:48.044698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad12374742f543f094b411b2d44a4d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=938)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_los: 5.355753008721566|last_bc: 5.1544280746220865|last_kl: 0.2013249340994643|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb5bb0caa6540e0b25be6cd1500d27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=938)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_los: 3.7176189176228056|last_bc: 3.334397504254201|last_kl: 0.3832214133686073|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1379cb95d0f54c26b427e53d776d1627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=938)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_los: 3.610533328194545|last_bc: 3.1006863089913734|last_kl: 0.5098470192031713|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc06eef9013479f8e1cde26726eadaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=938)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_los: 4.013215080376414|last_bc: 3.211266124418773|last_kl: 0.8019489559576428|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5857fa924e514eb3b6313b8294a84131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=938)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_los: 4.485466936876943|last_bc: 3.334403744061753|last_kl: 1.1510631928151922|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9095ce0da182424da2c12e97b4f5ee68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=938)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_los: 4.649772527748089|last_bc: 3.321271505952707|last_kl: 1.3285010217953936|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5daaaafdf11749d69d648169c16beec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=938)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_los: 5.767105431301311|last_bc: 3.37754143650536|last_kl: 2.389563994795943|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10de3e78debf45178457eefa9af04b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=938)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_los: 7.375192984806674|last_bc: 3.531659190156688|last_kl: 3.8435337946499772|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8948f9146a52453ea9351cc47125ce5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=938)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-ea49d0e60082>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-0c3ee828e775>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae_trainer.train(num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to use tensorboard:\n",
    "- prepare:\n",
    "    - Update the fire wall setting `Allow SSH from anywhere` and set tcp:6006 and priority 1 (don't know if this is the key)\n",
    "- before training: \n",
    "    - close old tensorboard (since it will be looking for an old file and raise errors in terminal)\n",
    "    - reinstantiate a Learner object\n",
    "    - start training\n",
    "- to access tensorboard:\n",
    "    - type in terminal: `tensorboard --logdir=runs/mnist --bind_all`\n",
    "    - type in url : `http://35.221.143.120:6006/` (use http instead of https)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first task tomorrow, change this code to work on cpu/gpu with one line of code\n",
    "# the reason why generation quality is low might be that generative models need to be trained a lot more\n",
    "# add org and recon visualizers, and set to 64 plots instead of 10\n",
    "# train this mnist model for 200 epochs and see what happens over time, backup the log file at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.444px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
